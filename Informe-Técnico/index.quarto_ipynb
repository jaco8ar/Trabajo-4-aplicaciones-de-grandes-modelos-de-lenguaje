{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "format:\n",
        "  html:\n",
        "    toc: true\n",
        "    toc-depth: 2\n",
        "    number-sections: true\n",
        "execute:\n",
        "  echo: false\n",
        "   \n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "```{=html}\n",
        "\n",
        "<style>\n",
        "    h2 {\n",
        "        border: none !important;\n",
        "        box-shadow: none !important;\n",
        "        border-bottom: none !important;\n",
        "    }\n",
        "</style>\n",
        "<div style=\"\n",
        "    background-color:rgb(255, 255, 255);\n",
        "    border-radius: 15px;\n",
        "    padding: 30px;\n",
        "    text-align: center;\n",
        "    font-family: Arial, sans-serif;\n",
        "    color: #333;\n",
        "    box-shadow: 0px 4px 10px rgba(0, 0, 0, 0.2);\">\n",
        "    <h1 style=\"color:rgb(26, 54, 97); font-size: 50px;\">Trabajo 4: Implementación del Agente Creativo de Historias con LLMs</h1>\n",
        "    <h2 style=\"color: #555;\">Redes Neuronales y Algoritmos Bioinspirados</h2>\n",
        "\n",
        "    <h3 style=\"color: #222; margin: 10px 0;\">Equipo:</h3>\n",
        "    <ul style=\"list-style: none; padding: 0; font-size: 20px;\">\n",
        "        <li>Juan José Correa Hurtado</li>\n",
        "        <li>Jacobo Ochoa Ramírez</li>\n",
        "    </ul>\n",
        "    <h3 style=\"color: #222; margin: 10px 0;\">Profesor:</h3>\n",
        "    <ul style=\"list-style: none; padding: 0; font-size: 20px;\">\n",
        "      <li>Juan David Ospina Arango</li>\n",
        "    </ul>\n",
        "    <h2 style=\"color: #555;\">Universidad Nacional de Colombia</h2>\n",
        "    <img src=\"imagenes/logo_UNAL.png\" alt=\"logo UNAL\" />\n",
        "</div>\n",
        "\n",
        "```\n",
        "\n",
        "# Introducción\n",
        "\n",
        "La inteligencia artificial generativa ha abierto nuevas posibilidades para la creación automatizada de contenidos. En este contexto, el presente proyecto explora el desarrollo de un agente interactivo que colabore con los usuarios en la creación de relatos cortos, combinando capacidades de procesamiento de lenguaje natural con una interfaz web accesible. \n",
        "\n",
        "El sistema, implementado con modelos de lenguaje de gran escala (LLMs) y desplegado mediante Streamlit, permite generar historias coherentes y estilísticamente ajustadas según distintos géneros narrativos. Los usuarios pueden definir elementos clave como personajes, escenarios y tono, ya sea a través de formularios estructurados o descripciones en lenguaje natural.\n",
        "\n",
        "Este informe detalla el diseño, la implementación, las funcionalidades principales y las oportunidades de mejora del sistema propuesto.\n",
        "\n",
        "# Descripción del Proyecto\n",
        "Este proyecto consiste en el desarrollo de un agente interactivo de generación de historias, diseñado para colaborar con los usuarios en la escritura de relatos cortos atractivos. El sistema permite generar historias de distintos géneros literarios, incorporando elementos narrativos especificados por el usuario, como personajes, escenarios y dispositivos de trama.\n",
        "\n",
        "## Funcionalidad Principal\n",
        "El agente implementa las siguientes funcionalidades clave:\n",
        "\n",
        "1. Módulo de Procesamiento de Entradas\n",
        "Se desarrolló un componente capaz de aceptar y validar entradas del usuario, permitiendo describir los elementos de la historia mediante distintos formatos: formularios estructurados, lenguaje natural o combinaciones de ambos. El sistema incluye validaciones dinámicas que proporcionan mensajes de error claros y sugerencias útiles ante entradas incompletas.\n",
        "\n",
        "1. Motor de Generación de Historias\n",
        "El núcleo generador del agente se conecta con modelos de lenguaje de gran escala (LLMs), especificamente con Deepseek chat. Se utilizan estrategias diferenciadas de generación según el género narrativo seleccionado. Las historias generadas tienen una longitud de entre 300 y 800 palabras, con especial atención en mantener la coherencia narrativa, una estructura sólida y un estilo narrativo acorde al género y tono.\n",
        "\n",
        "1. Interfaz de Usuario\n",
        "Se diseñó una interfaz web interactiva que permite a los usuarios ingresar sus preferencias de manera intuitiva. La interfaz muestra las historias generadas en un formato claro y legible, y ofrece opciones para regenerar o refinar el relato. \n",
        "\n",
        "### Elementos Narrativos Considerados\n",
        "\n",
        "El sistema permite a los usuarios personalizar la historia a partir de los siguientes elementos:\n",
        "\n",
        "* Personajes: Nombre, rol, rasgos de personalidad y relaciones entre ellos.\n",
        "\n",
        "* Escenario: Ubicación, época histórica y atmósfera general del relato.\n",
        "\n",
        "* Género: Fantasía, misterio, romance, terror, ciencia ficción, comedia o aventura.\n",
        "\n",
        "* Elementos de Trama: Tipo de conflicto.\n",
        "\n",
        "* Tono: Humorístico, oscuro, caprichoso, dramático o satírico.\n",
        "\n",
        "* Longitud Preferida: Corta (300–400 palabras), mediana (400–600 palabras) o larga (600–800 palabras).\n",
        "\n",
        "\n",
        "\n",
        "# Objetivos del proyecto\n",
        "\n",
        "El sistema tiene como objetivo:\n",
        "\n",
        "- Generar historias coherentes y atractivas basadas en entradas del usuario, ya sea en formato libre o estructurado.\n",
        "- Soportar múltiples géneros narrativos (fantasía, misterio, romance, terror, ciencia ficción, comedia, aventura).\n",
        "- Validar y procesar entradas del usuario para garantizar calidad en las historias generadas.\n",
        "- Permitir refinamiento interactivo de historias generadas.\n",
        "- Construir historias coherentes y aptas para su público objetivo.\n",
        "- Identificar estrategias para la construcción de prompts efectivos en el uso de LLMs.\n",
        "- Ofrecer una interfaz web intuitiva utilizando Streamlit.\n",
        "\n",
        "---\n",
        "\n",
        "# Arquitectura del Sistema\n",
        "La implementación sigue una arquitectura modular dividida en varios componentes:\n",
        "\n",
        "1. **Módulo de Procesamiento de Entradas** ('validator.py'):\n",
        "   - Extrae elementos narrativos clave (personaje, rol, género, escenario, conflicto) utilizando un LLM para procesar texto libre.\n",
        "   - Evalúa la aptitud de una historia para un público especifico mediante un LLM.\n",
        "2. **Motor de Generación de Historias** ('generation.py', 'prompts.py'):\n",
        "   - Construye prompts específicos por género e interactúa con la API de OpenRouter (modelo '\"deepseek/deepseek-chat-v3-0324:free\"') para generar historias.\n",
        "   - Maneja la longitud de las historias (corta: ~400 palabras, mediana: ~600 palabras, larga: ~800 palabras) y realiza refinamiento si la respuesta excede los límites.\n",
        "   - Crea prompts a partir de las especificaciones del usuario.\n",
        "   - Permite al usuario realizar correcciones o sugerencias a las historias que ha construido mediante un proceso iterativo.\n",
        "3. **Interfaz de Usuario** ('modo_formulario.py', 'modo_texto_libre.py','formularios_genero'):\n",
        "   - Implementa una interfaz web con Streamlit que ofrece dos modos: formulario estructurado y texto libre.\n",
        "   - Permite a los usuarios generar y refinar historias de manera interactiva.\n",
        "   - Permite la especificación a profundidad y personalización de la historia generada.\n",
        "4. **Integraciones Externas**:\n",
        "   - Utiliza la API de OpenRouter para interactuar con el LLM '\"deepseek/deepseek-chat-v3-0324:free\"'.\n",
        "   - Gestiona claves de API a través de variables de entorno.\n",
        "\n",
        "**Diagrama de Arquitectura**:"
      ],
      "id": "673120c5"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from graphviz import Digraph\n",
        "\n",
        "dot = Digraph()\n",
        "\n",
        "dot.node(\"U\", \"Usuario\")\n",
        "dot.node(\"S\", \"Streamlit UI:\\nFormulario/Texto Libre\")\n",
        "dot.node(\"V\", \"Procesamiento de Entradas:\\nvalidator.py / modo_*.py\")\n",
        "dot.node(\"G\", \"Motor de Generación:\\ngeneration.py / prompts.py\")\n",
        "dot.node(\"A\", \"API OpenRouter:\\ndeepseek / deepseek-chat\")\n",
        "dot.node(\"H\", \"Salida:\\nHistoria Generada / Refinada\")\n",
        "dot.node(\"R\", \"Usuario:\\nVisualización en Streamlit\")\n",
        "\n",
        "dot.edge(\"U\", \"S\")\n",
        "dot.edge(\"S\", \"V\")\n",
        "dot.edge(\"V\", \"G\")\n",
        "dot.edge(\"G\", \"A\")\n",
        "dot.edge(\"A\", \"H\")\n",
        "dot.edge(\"H\", \"R\")\n",
        "\n",
        "dot.render(\"flujo_sistema\", format=\"png\", cleanup=True)"
      ],
      "id": "360ff3d1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Implementación\n",
        "La implementación está escrita en Python y utiliza varias bibliotecas y herramientas para cumplir con los requisitos del proyecto. A continuación, se describen los detalles clave de cada módulo:\n",
        "\n",
        "## Módulo de Procesamiento de Entradas\n",
        "- **Archivo**: `validator.py`, `modo_texto_libre.py`, `modo_formulario.py`, `formularios_genero.py`\n",
        "- **Funcionalidad**:\n",
        "  - **Validación de texto libre** (`validator.py`):\n",
        "    - Utiliza el LLM `deepseek/deepseek-chat` para analizar texto libre y extraer elementos narrativos (personaje, rol, género, escenario, conflicto).\n",
        "    - Devuelve un JSON con un indicador `es_historia` (si el texto es una solicitud válida) y los elementos extraídos.\n",
        "    - Maneja reintentos (máximo 2) en caso de respuestas inválidas o errores de formato JSON.\n",
        "  - **Modo formulario** (`modo_formulario.py`, `formularios_genero.py`):\n",
        "    - Proporciona un formulario interactivo en Streamlit con campos comunes (personaje, rol, personalidad, escenario, atmósfera, conflicto, tono, longitud) y campos específicos por género (ejemplo: raza y magia para fantasía, crimen y pistas para misterio).\n",
        "    - Almacena los datos en un diccionario para su uso en la generación de prompts.\n",
        "  - **Modo texto libre** (`modo_texto_libre.py`):\n",
        "    - Permite al usuario ingresar una descripción en lenguaje natural.\n",
        "    - Valida la entrada y muestra advertencias si faltan elementos clave, con opción de generar la historia de todas formas.\n",
        "- **Tecnologías**:\n",
        "  - `openai`: Cliente para interactuar con la API de OpenRouter.\n",
        "  - `streamlit`: Para crear formularios y mostrar resultados.\n",
        "  - `json`: Para procesar respuestas del LLM en formato JSON.\n",
        "  - `dotenv`: Para gestionar claves de API.\n",
        "\n",
        "## Motor de Generación de Historias\n",
        "- **Archivo**: `generation.py`, `prompts.py`\n",
        "- **Funcionalidad**:\n",
        "  - **Construcción de prompts** (`prompts.py`):\n",
        "    - Define funciones específicas por género (`prompt_extra_*`) que añaden detalles narrativos relevantes (ejemplo: criaturas mágicas para fantasía, enigmas para misterio).\n",
        "    - Construye un prompt base que incluye estructura narrativa (introducción, desarrollo, resolución), personaje, escenario, conflicto, tono, y longitud deseada.\n",
        "    - Utiliza un diccionario `funciones_genero` para mapear géneros a sus respectivas funciones de prompts.\n",
        "  - **Generación de historias** (`generation.py`):\n",
        "    - Interactúa con la API de OpenRouter usando el modelo `deepseek/deepseek-chat`.\n",
        "    - Mapea longitudes de historias (corta: 550 tokens/~400 palabras, mediana: 800 tokens/~600 palabras, larga: 1100 tokens/~800 palabras).\n",
        "    - Maneja casos en que la respuesta excede el límite de tokens, generando una versión más corta con un prompt ajustado.\n",
        "  - **Refinamiento de historias** (`generation.py`):\n",
        "    - Permite modificar una historia existente según sugerencias del usuario, manteniendo el contexto original (formulario o texto libre).\n",
        "    - Usa un nuevo mensaje al LLM con la historia original y la sugerencia de cambio.\n",
        "- **Tecnologías**:\n",
        "  - `openai`: Cliente para la API de OpenRouter.\n",
        "  - `requests`: Para manejar errores de conexión.\n",
        "  - `dotenv`: Para cargar claves de API desde un archivo `.env`.\n",
        "\n",
        "## Interfaz de Usuario\n",
        "- **Archivo**: `modo_formulario.py`, `modo_texto_libre.py`\n",
        "- **Funcionalidad**:\n",
        "  - **Modo formulario**:\n",
        "    - Presenta un formulario en Streamlit con campos predefinidos y específicos por género.\n",
        "    - Al enviar el formulario, genera la historia y la muestra en la interfaz.\n",
        "    - Permite refinamiento mediante un formulario adicional para sugerencias.\n",
        "  - **Modo texto libre**:\n",
        "    - Ofrece un área de texto para descripciones en lenguaje natural.\n",
        "    - Valida la entrada y sugiere mejoras si faltan elementos clave.\n",
        "    - Muestra la historia generada y permite refinamiento.\n",
        "- **Tecnologías**:\n",
        "  - `streamlit`: Framework para la interfaz web.\n",
        "  - Sesiones de estado (`st.session_state`) para almacenar datos como la historia generada y los parámetros de entrada.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "# Evaluación\n",
        "## Cumplimiento de Requisitos\n",
        "- **Procesamiento de Entradas**:\n",
        "  - Soporta entradas estructuradas (formularios) y en lenguaje natural (texto libre).\n",
        "  - Valida entradas con retroalimentación clara (advertencias sobre elementos faltantes).\n",
        "  - Usa un LLM para extraer elementos narrativos en modo texto libre.\n",
        "- **Generación de Historias**:\n",
        "  - Genera historias coherentes de 300-800 palabras según la longitud seleccionada.\n",
        "  - Implementa estrategias específicas por género mediante prompts personalizados.\n",
        "  - Integra la API de OpenRouter (`deepseek/deepseek-chat`) para generación de texto.\n",
        "- **Interfaz de Usuario**:\n",
        "  - Ofrece una interfaz web intuitiva con Streamlit, con soporte para formularios y texto libre.\n",
        "  - Permite regenerar y refinar historias de manera interactiva.\n",
        "- **Funcionalidad Opcional (Imágenes)**:\n",
        "  - No se implementó la generación de imágenes, lo cual era un bonus opcional.\n",
        "\n",
        "## Métricas de Evaluación\n",
        "- **Coherencia narrativa**: Las historias generadas mantienen una estructura clara (introducción, desarrollo, resolución) gracias a los prompts estructurados.\n",
        "- **Robustez**: El sistema maneja errores de conexión y respuestas inválidas con reintentos y mensajes de error claros.\n",
        "- **Usabilidad**: La interfaz de Streamlit es intuitiva, con formularios bien organizados y retroalimentación inmediata.\n",
        "- **Tiempo de respuesta**: Depende de la API de OpenRouter, pero el diseño asíncrono de Streamlit asegura una experiencia fluida.\n",
        "\n",
        "## Limitaciones Observadas\n",
        "- **Dependencia de la API**: El sistema depende completamente de OpenRouter, lo que lo hace vulnerable a problemas de conectividad o límites de la API.\n",
        "- **Validación limitada**: Aunque valida elementos clave, no implementa reglas avanzadas para detectar incoherencias semánticas en las entradas.\n",
        "- **Falta de generación de imágenes**: La funcionalidad opcional de generar imágenes no está implementada.\n",
        "- **Escalabilidad**: No hay optimizaciones para manejar múltiples usuarios simultáneamente.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "# Posibles Mejoras\n",
        "- **Generación de Imágenes**: Integrar APIs como DALL-E o Stable Diffusion para generar ilustraciones basadas en las historias.\n",
        "- **Validación Avanzada**: Implementar reglas más sofisticadas para detectar incoherencias en las entradas (ejemplo: conflictos incompatibles con el género).\n",
        "- **Multilingüismo**: Permitir generar historias en diferentes idiomas utilizando modelos multilingües como mT5 o LLaMA.\n",
        "- **Almacenamiento de Historias**: Implementar una base de datos (SQLite o MongoDB) para guardar historias generadas y permitir a los usuarios recuperarlas.\n",
        "- **Optimización de Rendimiento**: Usar caché para prompts frecuentes y optimizar llamadas a la API para reducir costos y tiempos de respuesta.\n",
        "- **Soporte Offline**: Integrar un modelo local (como LLaMA) para reducir la dependencia de APIs externas.\n",
        "\n",
        "---\n",
        "\n",
        "# Conclusión\n",
        "La implementación del **Agente Creativo de Historias con LLMs** es un sistema robusto y funcional que cumple con la mayoría de los requisitos establecidos. La arquitectura modular, el uso de Streamlit para la interfaz, y la integración con la API de OpenRouter permiten generar historias coherentes y personalizadas de manera interactiva. Aunque carece de la funcionalidad opcional de generación de imágenes, el sistema es extensible y puede mejorarse con las sugerencias propuestas. Este proyecto demuestra un uso efectivo de LLMs para aplicaciones creativas, con potencial en educación, entretenimiento y escritura asistida.\n",
        "Por otro lado, queda claro que hay un límite a cuánto se puede modificar los prompts para evitar que se den incorehencias en la historia, pues en caso del usuario desearlo puede darle especificaciones contradictorias al agente a tal punto que no se pueda crear una historia coherente a partir de estas. La facilidad y rápidez que estos modelos se acomodan a las instrucciones entregadas puede ahorrar una cantidad de tiempo y esfuerzo incalculable para ciertos trabajos pero siempre es importante recordar sus limitaciones y que son una herramienta.\n",
        "\n",
        "---\n",
        "\n",
        "**Referencias**:\n",
        "- Repositorio: https://github.com/jaco8ar/Trabajo-4-aplicaciones-de-grandes-modelos-de-lenguaje\n",
        "- Documentación de OpenRouter: https://openrouter.ai/docs\n",
        "- Documentación de Streamlit: https://docs.streamlit.io\n",
        "- Gomila, J. G. (2024b, diciembre 17). Dominando la IA Generativa y la ingeniería de LLMs - Recursos. Frogames. https://cursos.frogamesformacion.com/pages/blog/ingenieria-de-llms-recursos\n",
        "- Large Language Models (LLMs) with Google AI. (s. f.). Google Cloud. https://cloud.google.com/ai/llms\n",
        "- Azure Microsoft. ¿Qué son los modelos de lenguaje de grandes (LLM). Microsoft. https://azure.microsoft.com/es-es/resources/cloud-computing-dictionary/what-are-large-language-models-llms#Resources\n"
      ],
      "id": "91091958"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\share\\jupyter\\kernels\\python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}